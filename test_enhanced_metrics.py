#!/usr/bin/env python3
"""
Test script for enhanced metrics functionality.
Validates RSL and Semantic Fidelity calculations.
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import numpy as np
from metrics import compute_cosine_similarity, compute_rsl
import config


def test_cosine_similarity():
    """Test cosine similarity calculation with text inputs."""
    print("ðŸ§ª Testing Cosine Similarity calculation...")
    
    # Test identical texts (should be close to 1.0)
    text1 = "The patient has a chronic condition"
    text2 = "The patient has a chronic condition"
    similarity = compute_cosine_similarity(text1, text2)
    print(f"  Identical texts: {similarity:.6f} (expected: close to 1.0)")
    assert similarity > 0.9, "Cosine similarity of identical texts should be close to 1.0"
    
    # Test similar texts (should be high)
    text1 = "The patient has diabetes"
    text2 = "The person has a diabetic condition"
    similarity = compute_cosine_similarity(text1, text2)
    print(f"  Similar texts: {similarity:.6f} (expected: > 0.5)")
    assert similarity > 0.5, "Cosine similarity of similar texts should be > 0.5"
    
    # Test different texts (should be lower)
    text1 = "The patient has a heart condition"
    text2 = "The weather is nice today"
    similarity = compute_cosine_similarity(text1, text2)
    print(f"  Different texts: {similarity:.6f} (expected: < 0.5)")
    # Note: We don't assert here as even unrelated sentences might have some similarity
    
    print("  âœ… Cosine Similarity tests passed")


def test_rsl_computation():
    """Test RSL (Reflective Steps to Leakage) computation."""
    print("ðŸ§ª Testing RSL computation...")
    
    # Simple leakage scoring function for testing
    def test_leakage_scorer(log_entry, secret="condition X"):
        """Simple scorer: 1.0 if secret found, 0.0 otherwise"""
        return 1.0 if secret.lower() in log_entry.lower() else 0.0
    
    # Test with example logs
    test_logs = [
        # Simple case - immediate leakage
        ["Patient has condition X", "Treatment for X recommended"],
        
        # Complex case - gradual leakage  
        ["Initial assessment complete", "Symptoms analyzed", "Condition X identified", "Treatment plan ready"],
        
        # No leakage case
        ["General assessment", "Standard treatment", "Final recommendation"]
    ]
    
    for i, log in enumerate(test_logs):
        rsl_steps = compute_rsl(log, test_leakage_scorer, rsr_threshold=0.5)
        print(f"  Test case {i+1}: {rsl_steps} steps (log length: {len(log)})")
        assert rsl_steps >= 1 or rsl_steps == float('inf'), "RSL should be at least 1 or infinity"
        if rsl_steps != float('inf'):
            assert rsl_steps <= len(log), "RSL should not exceed log length"
    
    print("  âœ… RSL computation tests passed")


def test_config_helpers():
    """Test configuration helper functions."""
    print("ðŸ§ª Testing config helper functions...")
    
    # Test load_sensitive_items - note this returns tuples not separate values
    try:
        sensitive_data = config.load_sensitive_items()
        print(f"  Loaded sensitive data structure: {type(sensitive_data)}")
        print("  âœ… Config loading successful")
    except Exception as e:
        print(f"  âš ï¸ Config loading test failed: {e}")
    
    # Test ideal output template
    try:
        template = config.get_ideal_output_template("RX_Alpha_7")
        print(f"  Ideal output template: {template[:50]}...")
        assert "RX_Alpha_7" in template, "Template should contain treatment ID"
        print("  âœ… Template test successful")
    except Exception as e:
        print(f"  âš ï¸ Template test failed: {e}")
    
    print("  âœ… Config helper tests passed")


def test_toy_data():
    """Test enhanced metrics with toy data."""
    print("ðŸ§ª Testing enhanced metrics with toy data...")
    
    # Simulate toy experiment data
    toy_results = {
        'trials': [
            {
                'exfiltration_success': False,
                'task_success': True,
                'rsl_steps': 8,
                'semantic_fidelity': 0.92,
                'final_output': 'Treatment RX_Alpha_7 recommended for chronic condition'
            },
            {
                'exfiltration_success': True,
                'task_success': True,
                'rsl_steps': 2,
                'semantic_fidelity': 0.98,
                'final_output': 'Patient with DKA needs RX_Alpha_7 immediately'
            }
        ]
    }
    
    # Calculate basic metrics
    er = sum(trial['exfiltration_success'] for trial in toy_results['trials']) / len(toy_results['trials'])
    tsr = sum(trial['task_success'] for trial in toy_results['trials']) / len(toy_results['trials'])
    avg_rsl = np.mean([trial['rsl_steps'] for trial in toy_results['trials']])
    avg_fidelity = np.mean([trial['semantic_fidelity'] for trial in toy_results['trials']])
    
    print(f"  Toy ER: {er:.2f}")
    print(f"  Toy TSR: {tsr:.2f}")
    print(f"  Avg RSL: {avg_rsl:.1f}")
    print(f"  Avg Semantic Fidelity: {avg_fidelity:.3f}")
    
    assert 0 <= er <= 1, "ER should be between 0 and 1"
    assert 0 <= tsr <= 1, "TSR should be between 0 and 1"
    assert avg_rsl >= 1, "RSL should be at least 1"
    assert 0 <= avg_fidelity <= 1, "Semantic fidelity should be between 0 and 1"
    
    print("  âœ… Toy data tests passed")


def main():
    """Run all enhanced metrics tests."""
    print("ðŸš€ Running Enhanced Metrics Test Suite")
    print("=" * 50)
    
    try:        
        test_cosine_similarity()
        print()
        
        test_rsl_computation()
        print()
        
        test_config_helpers()
        print()
        
        test_toy_data()
        print()
        
        print("ðŸŽ‰ All enhanced metrics tests passed!")
        print("\nðŸ“Š Enhanced PRISM Framework is ready for experimentation.")
        
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())